# -*- coding: utf-8 -*-
"""Untitled

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1x5cX8Jfq-jcDyWUk26BGi0y_Vi96tm_Z
"""

from google.colab import drive
drive.mount('/content/drive')

import tensorflow as tf
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from tensorflow.keras.utils import Sequence
from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Input, concatenate
from tensorflow.keras.models import Model
from PIL import Image
import io
import h5py
import gc
import matplotlib.pyplot as plt
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Define the paths to your data
hdf5_file_path = '/content/drive/My Drive/isic-2024-challenge/train-image.hdf5'
metadata_path = '/content/drive/My Drive/isic-2024-challenge/train-metadata.csv'

# Load the HDF5 image data
hdf5_file = h5py.File(hdf5_file_path, 'r')

# Load metadata CSV file
metadata = pd.read_csv(metadata_path)

# Select a subset of columns from metadata
metadata_columns = ['age_approx', 'sex', 'anatom_site_general', 'isic_id', 'target']
metadata_clean = metadata[metadata_columns].copy()

# Fill missing values
metadata_clean['age_approx'].fillna(metadata_clean['age_approx'].mean(), inplace=True)
metadata_clean['sex'].fillna('unknown', inplace=True)
metadata_clean['anatom_site_general'].fillna('unknown', inplace=True)

# Convert categorical data to one-hot encoding
metadata_clean = pd.get_dummies(metadata_clean, drop_first=True)

# Standardize numeric columns
scaler = StandardScaler()
metadata_clean['age_approx'] = scaler.fit_transform(metadata_clean[['age_approx']])

# Separate features (X_meta) and target labels (y)
X_meta = metadata_clean.drop(columns=['isic_id', 'target']).values
y = metadata_clean['target'].values

import pandas as pd
from sklearn.preprocessing import StandardScaler, LabelEncoder
import numpy as np
import h5py
from PIL import Image
from tensorflow.keras.utils import Sequence
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import matplotlib.pyplot as plt
import gc
import io

# Path to your HDF5 and metadata files
hdf5_file_path = '/content/drive/My Drive/isic-2024-challenge/train-image.hdf5'
metadata_path = '/content/drive/My Drive/isic-2024-challenge/train-metadata.csv'

# Load metadata from the CSV file
metadata = pd.read_csv(metadata_path)

# Ensure metadata is loaded properly
print(metadata.head())  # To confirm it's loaded correctly

# Fill missing values
metadata['age_approx'].fillna(metadata['age_approx'].mean(), inplace=True)
metadata['sex'].fillna('unknown', inplace=True)
metadata['anatom_site_general'].fillna('unknown', inplace=True)

# Label encoding for categorical features
label_encoder_sex = LabelEncoder()
label_encoder_anatom = LabelEncoder()
metadata['sex'] = label_encoder_sex.fit_transform(metadata['sex'])
metadata['anatom_site_general'] = label_encoder_anatom.fit_transform(metadata['anatom_site_general'])

# Scale 'age_approx'
scaler = StandardScaler()
metadata['age_approx'] = scaler.fit_transform(metadata[['age_approx']])

# Split metadata into X_meta and target (y)
X_meta = metadata[['age_approx', 'sex', 'anatom_site_general']].values
y = metadata['target'].values
image_ids = metadata['isic_id'].values

# Split data into train and validation sets
from sklearn.model_selection import train_test_split
X_meta_train, X_meta_val, y_train, y_val = train_test_split(X_meta, y, test_size=0.2, random_state=42)
image_ids_train, image_ids_val = train_test_split(image_ids, test_size=0.2, random_state=42)

# Custom Data Generator to load images and metadata in batches
class BatchImageDataGenerator(Sequence):
    def __init__(self, hdf5_file_path, image_ids, metadata, labels, batch_size=32, img_shape=(224, 224), augment=False):
        self.hdf5_file_path = hdf5_file_path
        self.image_ids = image_ids
        self.metadata = metadata
        self.labels = labels
        self.batch_size = batch_size
        self.img_shape = img_shape
        self.augment = augment
        self.indexes = np.arange(len(self.image_ids))

        # Augmentation setup
        self.datagen = ImageDataGenerator(
            rotation_range=20,
            zoom_range=0.15,
            width_shift_range=0.1,
            height_shift_range=0.1,
            horizontal_flip=True
        )

    def __len__(self):
        return int(np.ceil(len(self.image_ids) / self.batch_size))

    def __getitem__(self, index):
        batch_indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]
        return self.__data_generation(batch_indexes)

    def __data_generation(self, batch_indexes):
        X_img = []
        X_meta = []
        y = []

        with h5py.File(self.hdf5_file_path, 'r') as hdf5_file:
            for i in batch_indexes:
                isic_id = self.image_ids[i]
                img_data = hdf5_file[isic_id][()]
                img = Image.open(io.BytesIO(img_data)).convert('RGB')
                img_resized = img.resize(self.img_shape)
                img_normalized = np.array(img_resized) / 255.0

                # Apply data augmentation if augment is set to True
                if self.augment:
                    img_normalized = self.datagen.random_transform(img_normalized)

                X_img.append(img_normalized)
                X_meta.append(self.metadata[i])
                y.append(self.labels[i])

        return np.array(X_img), np.array(X_meta), np.array(y)

    def on_epoch_end(self):
        np.random.shuffle(self.indexes)
        gc.collect()

# Create train and validation generators
train_generator = BatchImageDataGenerator(
    hdf5_file_path,
    image_ids_train,
    X_meta_train,
    y_train,
    batch_size=16,  # Adjust batch size depending on memory
    img_shape=(224, 224),
    augment=True
)

val_generator = BatchImageDataGenerator(
    hdf5_file_path,
    image_ids_val,
    X_meta_val,
    y_val,
    batch_size=16,  # Same batch size for validation
    img_shape=(224, 224),
    augment=False
)

# Display a processed image from the training generator
X_sample, _, _ = train_generator[0]  # First batch
plt.imshow(X_sample[0])
plt.axis('off')
plt.show()

# Example: Train the CNN model (assuming your model is already defined)
# model.fit(train_generator, validation_data=val_generator, epochs=10)

# Correct the variable to use 'metadata' if it's already cleaned and consistent
X_meta_train, X_meta_val, y_train, y_val = train_test_split(X_meta, y, test_size=0.2, random_state=42)
image_ids_train, image_ids_val = train_test_split(metadata['isic_id'].values, test_size=0.2, random_state=42)

class ImageDataGeneratorWithMetadata(Sequence):
    def __init__(self, hdf5_file_path, image_ids, metadata, labels, batch_size=16, img_shape=(224, 224), augment=False):
        self.hdf5_file_path = hdf5_file_path
        self.image_ids = image_ids
        self.metadata = metadata
        self.labels = labels
        self.batch_size = batch_size
        self.img_shape = img_shape
        self.augment = augment
        self.indexes = np.arange(len(self.image_ids))

        # Define data augmentation if required
        self.datagen = ImageDataGenerator(
            rotation_range=20,
            zoom_range=0.15,
            width_shift_range=0.1,
            height_shift_range=0.1,
            horizontal_flip=True
        )

    def __len__(self):
        return int(np.ceil(len(self.image_ids) / self.batch_size))

    def __getitem__(self, index):
        batch_indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]
        return self.__data_generation(batch_indexes)

    def __data_generation(self, batch_indexes):
        X_img = []
        X_meta = []
        y = []

        with h5py.File(self.hdf5_file_path, 'r') as hdf5_file:  # Load HDF5 file only when needed
            for i in batch_indexes:
                # Load the image
                isic_id = self.image_ids[i]
                img_data = hdf5_file[isic_id][()]
                img = Image.open(io.BytesIO(img_data)).convert('RGB')
                img_resized = img.resize(self.img_shape)
                img_normalized = np.array(img_resized) / 255.0

                # Apply data augmentation if specified
                if self.augment:
                    img_normalized = self.datagen.random_transform(img_normalized)

                X_img.append(img_normalized)
                X_meta.append(self.metadata[i])

                y.append(self.labels[i])

        return [np.array(X_img), np.array(X_meta)], np.array(y)

    def on_epoch_end(self):
        """Shuffle indexes after each epoch to avoid bias."""
        np.random.shuffle(self.indexes)
        gc.collect()

# Train and validation generators
train_generator = ImageDataGeneratorWithMetadata(hdf5_file_path, image_ids_train, X_meta_train, y_train, batch_size=16, augment=True)
val_generator = ImageDataGeneratorWithMetadata(hdf5_file_path, image_ids_val, X_meta_val, y_val, batch_size=16, augment=False)

# Image input
image_input = Input(shape=(224, 224, 3), name='image_input')
x = Conv2D(32, kernel_size=(3, 3), activation='relu')(image_input)
x = MaxPooling2D(pool_size=(2, 2))(x)
x = Conv2D(64, kernel_size=(3, 3), activation='relu')(x)
x = MaxPooling2D(pool_size=(2, 2))(x)
x = Flatten()(x)

# Metadata input
meta_input = Input(shape=(X_meta_train.shape[1],), name='meta_input')
meta = Dense(64, activation='relu')(meta_input)
meta = Dropout(0.5)(meta)

# Concatenate image and metadata inputs
combined = concatenate([x, meta])

# Fully connected layers
fc = Dense(128, activation='relu')(combined)
fc = Dropout(0.5)(fc)
output = Dense(1, activation='sigmoid')(fc)

# Define the model
model = Model(inputs=[image_input, meta_input], outputs=output)
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Model summary
model.summary()

# Train the model
history = model.fit(
    train_generator,
    validation_data=val_generator,
    epochs=10
)

# Plot the training and validation accuracy/loss
plt.plot(history.history['accuracy'], label='accuracy')
plt.plot(history.history['val_accuracy'], label = 'val_accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.ylim([0, 1])
plt.legend(loc='lower right')
plt.show()

import tensorflow as tf
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from tensorflow.keras.utils import Sequence
from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Input, concatenate
from tensorflow.keras.models import Model
from PIL import Image
import io
import h5py
import gc
import matplotlib.pyplot as plt
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Load metadata CSV file
metadata_path = '/content/drive/My Drive/isic-2024-challenge/train-metadata.csv'
metadata = pd.read_csv(metadata_path)

# Fill missing values and encode categorical data
metadata['age_approx'].fillna(metadata['age_approx'].mean(), inplace=True)
metadata['sex'].fillna('unknown', inplace=True)
metadata['anatom_site_general'].fillna('unknown', inplace=True)

# Encode categorical variables
label_encoder_sex = LabelEncoder()
label_encoder_anatom = LabelEncoder()
metadata['sex'] = label_encoder_sex.fit_transform(metadata['sex'])
metadata['anatom_site_general'] = label_encoder_anatom.fit_transform(metadata['anatom_site_general'])

# Standardize 'age_approx'
scaler = StandardScaler()
metadata['age_approx'] = scaler.fit_transform(metadata[['age_approx']])

# Split metadata into features and target
X_meta = metadata[['age_approx', 'sex', 'anatom_site_general']].values
y = metadata['target'].values
image_ids = metadata['isic_id'].values

# Split into train and validation sets
X_meta_train, X_meta_val, y_train, y_val = train_test_split(X_meta, y, test_size=0.2, random_state=42)
image_ids_train, image_ids_val = train_test_split(image_ids, test_size=0.2, random_state=42)

# Custom Data Generator to load images and metadata in batches
class BatchImageDataGenerator(Sequence):
    def __init__(self, hdf5_file_path, image_ids, metadata, labels, batch_size=32, img_shape=(224, 224), augment=False):
        self.hdf5_file_path = hdf5_file_path
        self.image_ids = image_ids
        self.metadata = metadata
        self.labels = labels
        self.batch_size = batch_size
        self.img_shape = img_shape
        self.augment = augment
        self.indexes = np.arange(len(self.image_ids))
        self.datagen = ImageDataGenerator(
            rotation_range=20,
            zoom_range=0.15,
            width_shift_range=0.1,
            height_shift_range=0.1,
            horizontal_flip=True
        )

    def __len__(self):
        return int(np.ceil(len(self.image_ids) / self.batch_size))

    def __getitem__(self, index):
        batch_indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]
        return self.__data_generation(batch_indexes)

    def __data_generation(self, batch_indexes):
        X_img = []
        X_meta = []
        y = []

        with h5py.File(self.hdf5_file_path, 'r') as hdf5_file:
            for i in batch_indexes:
                isic_id = self.image_ids[i]
                img_data = hdf5_file[isic_id][()]
                img = Image.open(io.BytesIO(img_data)).convert('RGB')
                img_resized = img.resize(self.img_shape)
                img_normalized = np.array(img_resized) / 255.0

                if self.augment:
                    img_normalized = self.datagen.random_transform(img_normalized)

                X_img.append(img_normalized)
                X_meta.append(self.metadata[i])
                y.append(self.labels[i])

        return [np.array(X_img), np.array(X_meta)], np.array(y)

    def on_epoch_end(self):
        np.random.shuffle(self.indexes)
        gc.collect()

# Train and validation generators
train_generator = BatchImageDataGenerator(
    hdf5_file_path='/content/drive/My Drive/isic-2024-challenge/train-image.hdf5',
    image_ids=image_ids_train,
    metadata=X_meta_train,
    labels=y_train,
    batch_size=16,
    augment=True
)

val_generator = BatchImageDataGenerator(
    hdf5_file_path='/content/drive/My Drive/isic-2024-challenge/train-image.hdf5',
    image_ids=image_ids_val,
    metadata=X_meta_val,
    labels=y_val,
    batch_size=16,
    augment=False
)

# Fairness constraint: Equal opportunity (True Positive Rate (TPR) parity)
def equal_opportunity_loss(y_true, y_pred, group):
    group0_mask = (group == 0)
    group1_mask = (group == 1)

    # True positives for each group
    group0_preds = tf.boolean_mask(y_pred, group0_mask)
    group0_true = tf.boolean_mask(y_true, group0_mask)
    group0_tp = tf.reduce_mean(tf.cast((group0_preds > 0.5) & (group0_true == 1), tf.float32))

    group1_preds = tf.boolean_mask(y_pred, group1_mask)
    group1_true = tf.boolean_mask(y_true, group1_mask)
    group1_tp = tf.reduce_mean(tf.cast((group1_preds > 0.5) & (group1_true == 1), tf.float32))

    # Fairness penalty: difference in true positive rates between groups
    fairness_penalty = tf.abs(group0_tp - group1_tp)

    # Regular binary cross-entropy loss
    base_loss = tf.keras.losses.binary_crossentropy(y_true, y_pred)

    # Combine base loss and fairness penalty
    return base_loss + 0.1 * fairness_penalty  # Adjust 0.1 for fairness loss weight

# Model definition
image_input = Input(shape=(224, 224, 3), name='image_input')
x = Conv2D(32, kernel_size=(3, 3), activation='relu')(image_input)
x = MaxPooling2D(pool_size=(2, 2))(x)
x = Conv2D(64, kernel_size=(3, 3), activation='relu')(x)
x = MaxPooling2D(pool_size=(2, 2))(x)
x = Flatten()(x)

meta_input = Input(shape=(X_meta_train.shape[1],), name='meta_input')
meta = Dense(64, activation='relu')(meta_input)
meta = Dropout(0.5)(meta)

# Combine image and metadata features
combined = concatenate([x, meta])

fc = Dense(128, activation='relu')(combined)
fc = Dropout(0.5)(fc)
output = Dense(1, activation='sigmoid')(fc)

model = Model(inputs=[image_input, meta_input], outputs=output)
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Training the model with fairness constraint
history = model.fit(
    train_generator,
    validation_data=val_generator,
    epochs=10
)

# Plot accuracy
plt.plot(history.history['accuracy'], label='accuracy')
plt.plot(history.history['val_accuracy'], label='val_accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.ylim([0, 1])
plt.legend(loc='lower right')
plt.show()

import tensorflow as tf
import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import train_test_split
from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Input, concatenate
from tensorflow.keras.models import Model
from PIL import Image
import io
import h5py
import gc
import matplotlib.pyplot as plt
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Path to HDF5 file and metadata
hdf5_file_path = '/content/drive/My Drive/isic-2024-challenge/train-image.hdf5'
metadata_path = '/content/drive/My Drive/isic-2024-challenge/train-metadata.csv'

# Load metadata CSV file
metadata = pd.read_csv(metadata_path)

# Preprocess metadata: fill missing values and encode categorical variables
metadata['age_approx'].fillna(metadata['age_approx'].mean(), inplace=True)
metadata['sex'].fillna('unknown', inplace=True)
metadata['anatom_site_general'].fillna('unknown', inplace=True)

# Label encoding for categorical features
label_encoder_sex = LabelEncoder()
label_encoder_anatom = LabelEncoder()
metadata['sex'] = label_encoder_sex.fit_transform(metadata['sex'])
metadata['anatom_site_general'] = label_encoder_anatom.fit_transform(metadata['anatom_site_general'])

# Scale 'age_approx'
scaler = StandardScaler()
metadata['age_approx'] = scaler.fit_transform(metadata[['age_approx']])

# Split metadata into features (X_meta) and labels (y)
X_meta = metadata[['age_approx', 'sex', 'anatom_site_general']].values
y = metadata['target'].values
image_ids = metadata['isic_id'].values

# Split into training and validation sets
X_meta_train, X_meta_val, y_train, y_val = train_test_split(X_meta, y, test_size=0.2, random_state=42)
image_ids_train, image_ids_val = train_test_split(image_ids, test_size=0.2, random_state=42)

# Custom Data Generator
class BatchImageDataGenerator(tf.keras.utils.Sequence):
    def __init__(self, hdf5_file_path, metadata, labels, batch_size=32, img_shape=(224, 224), augment=False):
        self.hdf5_file_path = hdf5_file_path
        self.metadata = metadata
        self.labels = labels
        self.batch_size = batch_size
        self.img_shape = img_shape
        self.augment = augment

        # Initialize ImageDataGenerator if augmentation is required
        if self.augment:
            self.datagen = ImageDataGenerator(
                rotation_range=20,
                width_shift_range=0.2,
                height_shift_range=0.2,
                shear_range=0.2,
                zoom_range=0.2,
                horizontal_flip=True,
                fill_mode='nearest'
            )
        else:
            self.datagen = None

        self.indexes = np.arange(len(self.metadata))
        self.on_epoch_end()

    def __len__(self):
        return int(np.floor(len(self.metadata) / self.batch_size))

    def __getitem__(self, index):
        batch_indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]
        return self._data_generation(batch_indexes)

    def _data_generation(self, batch_indexes):
        X_img = []
        X_meta = []
        y = []
        sensitive_groups = []

        with h5py.File(self.hdf5_file_path, 'r') as hdf5_file:
            for i in batch_indexes:
                isic_id = self.metadata.iloc[i]['isic_id']
                img_data = hdf5_file[isic_id][()]
                img = Image.open(io.BytesIO(img_data)).convert('RGB')
                img_resized = img.resize(self.img_shape)
                img_normalized = np.array(img_resized) / 255.0

                if self.augment and self.datagen is not None:
                    img_normalized = self.datagen.random_transform(img_normalized)

                X_img.append(img_normalized)

                # Find the row in metadata corresponding to the current isic_id
                metadata_row = self.metadata[self.metadata['isic_id'] == isic_id].iloc[0]
                X_meta.append(metadata_row[['age_approx', 'sex', 'anatom_site_general']].values.astype(np.float32))
                y.append(metadata_row['target'].astype(np.float32))
                sensitive_groups.append(metadata_row['sex'])

        # Return inputs (image and metadata), target (y), and sensitive attribute (sensitive_groups)
        return [np.array(X_img), np.array(X_meta)], np.array(y, dtype=np.float32), np.array(sensitive_groups)

    def on_epoch_end(self):
        np.random.shuffle(self.indexes)
        gc.collect()

# Instantiate the generators
train_generator = BatchImageDataGenerator(
    hdf5_file_path,
    metadata[metadata['isic_id'].isin(image_ids_train)],
    y_train,
    batch_size=16,
    augment=True
)
val_generator = BatchImageDataGenerator(
    hdf5_file_path,
    metadata[metadata['isic_id'].isin(image_ids_val)],
    y_val,
    batch_size=16,
    augment=False
)

# CNN model definition for image input
image_input = Input(shape=(224, 224, 3), name='image_input')
x = Conv2D(32, kernel_size=(3, 3), activation='relu')(image_input)
x = MaxPooling2D(pool_size=(2, 2))(x)
x = Conv2D(64, kernel_size=(3, 3), activation='relu')(x)
x = MaxPooling2D(pool_size=(2, 2))(x)
x = Flatten()(x)

# Metadata input
meta_input = Input(shape=(X_meta_train.shape[1],), name='meta_input')
meta = Dense(64, activation='relu')(meta_input)
meta = Dropout(0.5)(meta)

# Concatenate image and metadata inputs
combined = concatenate([x, meta])

# Fully connected layers
fc = Dense(128, activation='relu')(combined)
fc = Dropout(0.5)(fc)
output = Dense(1, activation='sigmoid')(fc)

# Define the model
model = Model(inputs=[image_input, meta_input], outputs=output)

# CAPSA-inspired Fairness Mechanism
class CapsaLoss(tf.keras.losses.Loss):
    def __init__(self):
        super().__init__()

    def call(self, y_true, y_pred, sensitive_groups):
        bce_loss = tf.keras.losses.binary_crossentropy(y_true, y_pred)

        group_indices = tf.unique(sensitive_groups)[0]
        accuracies = []

        for group in group_indices:
            group_mask = tf.equal(sensitive_groups, group)
            group_y_true = tf.boolean_mask(y_true, group_mask)
            group_y_pred = tf.boolean_mask(y_pred, group_mask)

            if tf.size(group_y_true) > 0:
                group_y_true = tf.cast(group_y_true, tf.float32)
                group_accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.round(group_y_pred), group_y_true), tf.float32))
                accuracies.append(group_accuracy)

        if accuracies:
            fairness_penalty = 0.1 * (tf.reduce_max(accuracies) - tf.reduce_min(accuracies))
        else:
            fairness_penalty = 0.0

        return bce_loss + fairness_penalty

# Custom loss wrapper function
capsa_loss = CapsaLoss()

# Custom training loop
optimizer = tf.keras.optimizers.Adam()

for epoch in range(10):  # Number of epochs
    print(f'Starting epoch {epoch+1}')

    for step in range(len(train_generator)):
        (X_img_batch, X_meta_batch), y_batch, sensitive_groups_batch = train_generator[step]

        with tf.GradientTape() as tape:
            y_pred_batch = model([X_img_batch, X_meta_batch], training=True)
            loss_value = capsa_loss(y_batch, y_pred_batch, sensitive_groups_batch)

        grads = tape.gradient(loss_value, model.trainable_weights)
        optimizer.apply_gradients(zip(grads, model.trainable_weights))

    print(f'Epoch {epoch+1} finished')

    # Optionally, validate on validation set
    for step in range(len(val_generator)):
        (X_img_val_batch, X_meta_val_batch), y_val_batch, _ = val_generator[step]
        y_val_pred = model([X_img_val_batch, X_meta_val_batch], training=False)
        val_loss = capsa_loss(y_val_batch, y_val_pred, sensitive_groups_batch)  # Validation loss

    print(f'Validation for epoch {epoch+1} finished')

# Plotting training accuracy and loss (to be extended with validation logic)
plt.plot(history.history['accuracy'], label='accuracy')
plt.plot(history.history['val_accuracy'], label='val_accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend(loc='lower right')
plt.show()

import tensorflow as tf
import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import train_test_split
from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Input, concatenate
from tensorflow.keras.models import Model
from PIL import Image
import io
import h5py
import gc
import matplotlib.pyplot as plt
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Path to HDF5 file and metadata
hdf5_file_path = '/content/drive/My Drive/isic-2024-challenge/train-image.hdf5'
metadata_path = '/content/drive/My Drive/isic-2024-challenge/train-metadata.csv'

# Load metadata CSV file
metadata = pd.read_csv(metadata_path)

# Preprocess metadata: fill missing values and encode categorical variables
metadata['age_approx'].fillna(metadata['age_approx'].mean(), inplace=True)
metadata['sex'].fillna('unknown', inplace=True)
metadata['anatom_site_general'].fillna('unknown', inplace=True)

# Label encoding for categorical features
label_encoder_sex = LabelEncoder()
label_encoder_anatom = LabelEncoder()
metadata['sex'] = label_encoder_sex.fit_transform(metadata['sex'])
metadata['anatom_site_general'] = label_encoder_anatom.fit_transform(metadata['anatom_site_general'])

# Scale 'age_approx'
scaler = StandardScaler()
metadata['age_approx'] = scaler.fit_transform(metadata[['age_approx']])

# Split metadata into features (X_meta) and labels (y)
X_meta = metadata[['age_approx', 'sex', 'anatom_site_general']].values
y = metadata['target'].values
image_ids = metadata['isic_id'].values

# Split into training and validation sets
X_meta_train, X_meta_val, y_train, y_val = train_test_split(X_meta, y, test_size=0.2, random_state=42)
image_ids_train, image_ids_val = train_test_split(image_ids, test_size=0.2, random_state=42)

# Custom Data Generator
class BatchImageDataGenerator(tf.keras.utils.Sequence):
    def __init__(self, hdf5_file_path, metadata, labels, batch_size=32, img_shape=(224, 224), augment=False):
        self.hdf5_file_path = hdf5_file_path
        self.metadata = metadata
        self.labels = labels
        self.batch_size = batch_size
        self.img_shape = img_shape
        self.augment = augment

        if self.augment:
            self.datagen = ImageDataGenerator(
                rotation_range=20,
                width_shift_range=0.2,
                height_shift_range=0.2,
                shear_range=0.2,
                zoom_range=0.2,
                horizontal_flip=True,
                fill_mode='nearest'
            )
        else:
            self.datagen = None

        self.indexes = np.arange(len(self.metadata))
        self.on_epoch_end()

    def __len__(self):
        return int(np.floor(len(self.metadata) / self.batch_size))

    def __getitem__(self, index):
        batch_indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]
        return self._data_generation(batch_indexes)

    def _data_generation(self, batch_indexes):
        X_img = []
        X_meta = []
        y = []
        sensitive_groups = []

        with h5py.File(self.hdf5_file_path, 'r') as hdf5_file:
            for i in batch_indexes:
                isic_id = self.metadata.iloc[i]['isic_id']
                img_data = hdf5_file[isic_id][()]
                img = Image.open(io.BytesIO(img_data)).convert('RGB')
                img_resized = img.resize(self.img_shape)
                img_normalized = np.array(img_resized) / 255.0

                if self.augment and self.datagen is not None:
                    img_normalized = self.datagen.random_transform(img_normalized)

                X_img.append(img_normalized)

                # Find the row in metadata corresponding to the current isic_id
                metadata_row = self.metadata[self.metadata['isic_id'] == isic_id].iloc[0]
                X_meta.append(metadata_row[['age_approx', 'sex', 'anatom_site_general']].values.astype(np.float32))
                y.append(metadata_row['target'].astype(np.float32))
                sensitive_groups.append(metadata_row['sex'])  # Assuming 'sex' is the sensitive attribute

        return [np.array(X_img), np.array(X_meta)], np.array(y), np.array(sensitive_groups)

    def on_epoch_end(self):
        np.random.shuffle(self.indexes)
        gc.collect()

# Instantiate the generators
train_generator = BatchImageDataGenerator(
    hdf5_file_path,
    metadata[metadata['isic_id'].isin(image_ids_train)],
    y_train,
    batch_size=16,
    augment=True
)
val_generator = BatchImageDataGenerator(
    hdf5_file_path,
    metadata[metadata['isic_id'].isin(image_ids_val)],
    y_val,
    batch_size=16,
    augment=False
)

# CNN model definition for image input
image_input = Input(shape=(224, 224, 3), name='image_input')
x = Conv2D(32, kernel_size=(3, 3), activation='relu')(image_input)
x = MaxPooling2D(pool_size=(2, 2))(x)
x = Conv2D(64, kernel_size=(3, 3), activation='relu')(x)
x = MaxPooling2D(pool_size=(2, 2))(x)
x = Flatten()(x)

# Metadata input
meta_input = Input(shape=(X_meta_train.shape[1],), name='meta_input')
meta = Dense(64, activation='relu')(meta_input)
meta = Dropout(0.5)(meta)

# Concatenate image and metadata inputs
combined = concatenate([x, meta])

# Fully connected layers
fc = Dense(128, activation='relu')(combined)
fc = Dropout(0.5)(fc)
output = Dense(1, activation='sigmoid')(fc)

# Define the model
model = Model(inputs=[image_input, meta_input], outputs=output)

# CAPSA-inspired Fairness Mechanism
class CapsaLoss:
    def __call__(self, y_true, y_pred, sensitive_groups):
        # Binary cross-entropy loss
        bce_loss = tf.keras.losses.binary_crossentropy(y_true, y_pred)

        # Unique sensitive groups (e.g., male/female)
        group_indices = tf.unique(sensitive_groups)[0]
        accuracies = []

        # Calculate accuracy for each group
        for group in group_indices:
            group_mask = tf.equal(sensitive_groups, group)
            group_y_true = tf.boolean_mask(y_true, group_mask)
            group_y_pred = tf.boolean_mask(y_pred, group_mask)

            if tf.size(group_y_true) > 0:
                group_y_true = tf.cast(group_y_true, tf.float32)
                group_accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.round(group_y_pred), group_y_true), tf.float32))
                accuracies.append(group_accuracy)

        # Fairness penalty: maximum difference between group accuracies
        if accuracies:
            fairness_penalty = 0.1 * (tf.reduce_max(accuracies) - tf.reduce_min(accuracies))
        else:
            fairness_penalty = 0.0

        # Total loss is binary cross-entropy plus the fairness penalty
        return bce_loss + fairness_penalty

# Instantiate the loss
capsa_loss = CapsaLoss()

# Custom training loop
optimizer = tf.keras.optimizers.Adam()

for epoch in range(10):  # Number of epochs
    print(f'Starting epoch {epoch+1}')

    for step in range(len(train_generator)):
        # Get the current batch of data
        (X_img_batch, X_meta_batch), y_batch, sensitive_groups_batch = train_generator[step]

        with tf.GradientTape() as tape:
            # Make predictions
            y_pred_batch = model([X_img_batch, X_meta_batch], training=True)
            # Compute the custom loss
            loss_value = capsa_loss(y_batch, y_pred_batch, sensitive_groups_batch)

        # Compute gradients and apply them
        grads = tape.gradient(loss_value, model.trainable_weights)
        optimizer.apply_gradients(zip(grads, model.trainable_weights))

    print(f'Epoch {epoch+1} finished')

    # Optionally, validate on validation set
    for step in range(len(val_generator)):
        (X_img_val_batch, X_meta_val_batch), y_val_batch, sensitive_groups_batch = val_generator[step]
        y_val_pred = model([X_img_val_batch, X_meta_val_batch], training=False)
        val_loss = capsa_loss(y_val_batch, y_val_pred, sensitive_groups_batch)

    print(f'Validation for epoch {epoch+1} finished')

# Plotting accuracy and loss can be added later based on the custom loop history.